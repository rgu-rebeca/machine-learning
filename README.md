# üè† Predicci√≥n de precios de Airbnb ‚Äì Machine Learning

## üìå Objetivo del proyecto
El objetivo de esta pr√°ctica es abordar un **problema realista de Machine Learning** siguiendo una metodolog√≠a correcta y buenas pr√°cticas vistas en clase.  
En concreto, se trata de un **problema de regresi√≥n**, cuyo fin es **predecir el precio de un alojamiento de Airbnb** a partir de las variables disponibles en el dataset.

M√°s all√° de obtener un buen resultado num√©rico, el foco principal del proyecto est√° en:
- La **calidad del proceso seguido**
- La **correcta preparaci√≥n de los datos**
- La **elecci√≥n razonada de modelos y m√©tricas**



## üìä Conjunto de datos
El dataset utilizado procede de **Airbnb** y ha sido obtenido mediante t√©cnicas de *web scraping*.  
Se trata de **datos reales**, por lo que contiene:
- Valores nulos
- Variables categ√≥ricas
- Outliers
- Posibles problemas de correlaci√≥n entre variables

Esto hace necesario un an√°lisis y limpieza de datos m√°s cuidadosos que en datasets sint√©ticos.



## üß† Metodolog√≠a seguida

El proyecto se ha desarrollado de forma **incremental**, comenzando por soluciones sencillas y aumentando progresivamente la complejidad.

### 1Ô∏è‚É£ Preparaci√≥n de los datos
- Divisi√≥n del dataset en **train** y **test**
- Separaci√≥n de la variable objetivo (*price*)

### 2Ô∏è‚É£ An√°lisis exploratorio de datos (EDA)
- Inspecci√≥n inicial: `head()`, `describe()`, `info()`, tipos de datos
- An√°lisis de valores nulos
- Estudio de **outliers**
- An√°lisis de **correlaci√≥n** entre variables
- Visualizaci√≥n mediante histogramas y matrices de correlaci√≥n

### 3Ô∏è‚É£ Preprocesamiento
- Eliminaci√≥n de variables:
  - Con alto porcentaje de valores nulos
  - Poco informativas (IDs, texto irrelevante)
  - Altamente correlacionadas
- Transformaci√≥n de variables categ√≥ricas:
  - *One-Hot Encoding*
  - *Target Encoding*
- Imputaci√≥n de valores nulos
- Escalado de variables num√©ricas cuando el modelo lo requiere

### 4Ô∏è‚É£ Selecci√≥n de variables
- Uso de modelos como **Random Forest** para analizar la importancia de las variables
- Selecci√≥n de las variables m√°s relevantes para el modelado final

### 5Ô∏è‚É£ Modelado
- Entrenamiento de distintos modelos de regresi√≥n
- Uso de **cross-validation**
- Comparaci√≥n de resultados entre modelos

### 6Ô∏è‚É£ Evaluaci√≥n
- Evaluaci√≥n del rendimiento en conjunto de test
- M√©tricas utilizadas:
  - MSE
  - R¬≤
  - RMSE
- Comparaci√≥n entre modelos para seleccionar el m√°s adecuado



## üìà Resultados
Los resultados obtenidos son **razonables**, teniendo en cuenta la complejidad y la naturaleza real del dataset.  
El √©nfasis del proyecto no est√° en maximizar la m√©trica, sino en garantizar:
- Un pipeline coherente
- Ausencia de errores conceptuales
- Correcta separaci√≥n entre train y test



## üìù Conclusiones
Este proyecto demuestra c√≥mo abordar un problema real de Machine Learning de forma estructurada, desde el an√°lisis exploratorio hasta la evaluaci√≥n del modelo.  
La pr√°ctica pone de manifiesto la importancia de la **limpieza de datos**, la **selecci√≥n de variables** y la **comparaci√≥n de modelos**, m√°s all√° de la m√©trica final obtenida.



## üõ†Ô∏è Tecnolog√≠as utilizadas
- Python
- Pandas
- NumPy
- Matplotlib / Seaborn
- Scikit-learn
- Jupyter Notebook

